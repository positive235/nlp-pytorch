{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C1W1_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgoDDQx_XaP0"
      },
      "source": [
        "# **Sentiment Analysis with Logistic Regression in Pytorch**\n",
        "\n",
        "Motivated from Coursera NLP specialization Course 1 Week 1 Assignment \"Sentiment analysis with logistic regression\", only using nltk, numpy, pandas, etc., **which was not implemented in pytorch or tensorflow**.\n",
        "\n",
        "- Credits:\n",
        "  - Coursera Natural Language Processing Specialization by Deeplearning.ai Course 1 Week 1 Assignment (https://www.coursera.org/learn/classification-vector-spaces-in-nlp/) \n",
        "  - Introduction to Deep learning in Pytorch (Korean) (https://wikidocs.net/60037)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aZssA6qa2zd",
        "outputId": "bf56ea13-e2d4-43f2-e42d-1f4c5e453b6a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo7iLmVUfISh"
      },
      "source": [
        "from nltk.corpus import twitter_samples\n",
        "# Select the set of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcjgAB2YfZH5"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LfL4XDWgwER"
      },
      "source": [
        "# Split the edata into two pieces, one for training and one for testing (validation set)\n",
        "train_size = int(0.8 * len(all_positive_tweets))\n",
        "test_size = len(all_positive_tweets) - train_size\n",
        "train_pos, test_pos = torch.utils.data.random_split(all_positive_tweets, [train_size, test_size])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhVLEpa-hG9e"
      },
      "source": [
        "train_neg, test_neg = torch.utils.data.random_split(all_negative_tweets, [train_size, test_size])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I9GNvrlhcy_"
      },
      "source": [
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjav3D8piRCn"
      },
      "source": [
        "# Combine positive and negative labels\n",
        "train_y = torch.cat([torch.ones(len(train_pos), 1), torch.zeros(len(train_neg), 1)], dim=0)\n",
        "test_y = torch.cat([torch.ones(len(test_pos), 1), torch.zeros(len(test_neg), 1)], dim=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psQ0ORkvj9qy",
        "outputId": "4cb072f1-fed1-4488-c7dc-7acfe8214688"
      },
      "source": [
        "# Print the shape train and test sets\n",
        "print(\"train_y.shape = \", train_y.size())\n",
        "print(\"test_y.shape = \", test_y.size())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_y.shape =  torch.Size([8000, 1])\n",
            "test_y.shape =  torch.Size([2000, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDk2LZQUrmh-"
      },
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "def process_tweet(tweet):\n",
        "  \"\"\"Process tweet function.\n",
        "  Input:\n",
        "    tweet: a string containing a tweet\n",
        "  Output:\n",
        "    tweets_clean: a list of words containing the processed tweet\n",
        "  \"\"\"\n",
        "  stemmer = PorterStemmer()\n",
        "  stopwords_english = stopwords.words('english')\n",
        "\n",
        "  # remove stock market stickers like $GE\n",
        "  tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "\n",
        "  # remove RT\n",
        "  tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "\n",
        "  # remove hyperlinks\n",
        "  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "\n",
        "  # remove hashtags\n",
        "  # only removing the hash # sign from the word\n",
        "  tweet = re.sub(r'#', '', tweet)\n",
        "\n",
        "  #tokenize tweets\n",
        "  tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "  tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "  tweets_clean = []\n",
        "\n",
        "  for word in tweet_tokens:\n",
        "    if (word not in stopwords_english and word not in string.punctuation):\n",
        "      stem_word = stemmer.stem(word)\n",
        "      tweets_clean.append(stem_word)\n",
        "\n",
        "  return tweets_clean\n",
        "\n",
        "\n",
        "def build_freqs(tweets, labels):\n",
        "  \"\"\"Build frequencies.\n",
        "  Input: \n",
        "    tweets: a list of tweets\n",
        "    labels: an m x 1 array with the sentiment label of each tweet (0 or 1)\n",
        "  Output:\n",
        "    freqs: a dictionary mapping each (word, sentiment) pair to its frequency\n",
        "  \"\"\"\n",
        "\n",
        "  labelList = torch.squeeze(labels).tolist()\n",
        "\n",
        "  freqs = {}\n",
        "  for label, tweet in zip(labelList, tweets):\n",
        "    for word in process_tweet(tweet):\n",
        "      pair = (word, label)\n",
        "      if pair in freqs:\n",
        "        freqs[pair] += 1\n",
        "      else:\n",
        "        freqs[pair] = 1\n",
        "  return freqs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gygnpbyLxwqt",
        "outputId": "b0837576-4732-4a0e-951b-5026c4171294"
      },
      "source": [
        "# create frequency dictionary\n",
        "freqs = build_freqs(train_x, train_y)\n",
        "\n",
        "# check the output\n",
        "print(\"type(freqs) = \" + str(type(freqs)))\n",
        "print(\"len(freqs) = \" + str(len(freqs.keys())))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type(freqs) = <class 'dict'>\n",
            "len(freqs) = 11256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA-j6sp6yDpM",
        "outputId": "966fb79f-b733-40b6-ee99-ce62bcdc744c"
      },
      "source": [
        "# test the function below\n",
        "print('This is an example of a positive tweet: \\n', train_x[0])\n",
        "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[0]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is an example of a positive tweet: \n",
            " @JYGClub thanks admin :)\n",
            "\n",
            "This is an example of the processed version of the tweet: \n",
            " ['thank', 'admin', ':)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Av6WOh0U78"
      },
      "source": [
        "def extract_features(tweet, freqs):\n",
        "  \"\"\"Extracting the features.\n",
        "  Input:\n",
        "    tweet: a list of words for one tweet\n",
        "    freqs: a dictionary corresponding to the frequencies of each tuple(word, label)\n",
        "  Output:\n",
        "    x: a feature vector of dimension (1,3)\n",
        "  \"\"\"\n",
        "\n",
        "  # process_tweet tokenizes, stems, and removes stopwords\n",
        "  word_l = process_tweet(tweet)\n",
        "\n",
        "  # 3 elements in the form of a 1 x 3 vector\n",
        "  x = torch.zeros((1,3))\n",
        "\n",
        "  # bias term is set to 1\n",
        "  x[0,0] = 1\n",
        "\n",
        "  for word in word_l:\n",
        "    # increment the word count for positive label 1\n",
        "    x[0,1] += freqs.get((word, 1), 0)\n",
        "    # increment the word count for negative label 0\n",
        "    x[0,2] += freqs.get((word, 0), 0)\n",
        "  \n",
        "  assert(x.size()== (1, 3))\n",
        "  return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttSjEzS22Zlz",
        "outputId": "a9cef11e-24a3-44fa-c865-41b4f7cd0bb0"
      },
      "source": [
        "# Check your function\n",
        "\n",
        "# test 1\n",
        "# test on training data\n",
        "tmp1 = extract_features(train_x[0], freqs)\n",
        "print(tmp1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0000e+00, 3.3400e+03, 8.7000e+01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJh7hJEN2c_X",
        "outputId": "a51bc8db-064a-4a52-ad9a-5f2c5eb7ca30"
      },
      "source": [
        "# test 2:\n",
        "# check for when the words are not in the freqs dictionary\n",
        "tmp2 = extract_features('blorb bleeeeb bloooob', freqs)\n",
        "print(tmp2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7yNQnq12m9V"
      },
      "source": [
        "# Training the model\n",
        "\n",
        "# collect the features 'x' and stack them into a matrix 'X'\n",
        "X = torch.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "  X[i, :] = extract_features(train_x[i], freqs)\n",
        "\n",
        "# training labels corresponding to X\n",
        "Y = train_y"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k34C95D4Z2W",
        "outputId": "c516d107-511d-4ed1-fb7f-47c2d6cac803"
      },
      "source": [
        "# source code below from -\n",
        "# source code URL #1: https://wikidocs.net/60037\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "X = torch.FloatTensor(X)\n",
        "Y = torch.FloatTensor(Y)\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_dim, output_dim)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.sigmoid(self.linear(X))\n",
        "\n",
        "model = LogisticRegression(3, 1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "num_iters = 1500\n",
        "\n",
        "for epoch in range(num_iters + 1):\n",
        "  \n",
        "  model.train()\n",
        "  hypothesis = model(X)\n",
        "  cost = F.binary_cross_entropy(hypothesis, Y)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "    correct_prediction = prediction.float() == Y\n",
        "    accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
        "    print('Epoch {:4d}/{} Cost: {:.6F} Accuracy {:2.2f}%'.format(\n",
        "        epoch, num_iters, cost.item(), accuracy * 100))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1500 Cost: 48.874947 Accuracy 50.20%\n",
            "Epoch  100/1500 Cost: 48.653866 Accuracy 50.20%\n",
            "Epoch  200/1500 Cost: 47.923008 Accuracy 50.20%\n",
            "Epoch  300/1500 Cost: 49.895924 Accuracy 50.00%\n",
            "Epoch  400/1500 Cost: 49.895882 Accuracy 50.00%\n",
            "Epoch  500/1500 Cost: 49.895836 Accuracy 50.00%\n",
            "Epoch  600/1500 Cost: 49.895798 Accuracy 50.00%\n",
            "Epoch  700/1500 Cost: 49.895748 Accuracy 50.00%\n",
            "Epoch  800/1500 Cost: 49.895702 Accuracy 50.00%\n",
            "Epoch  900/1500 Cost: 49.895657 Accuracy 50.00%\n",
            "Epoch 1000/1500 Cost: 5.486577 Accuracy 94.10%\n",
            "Epoch 1100/1500 Cost: 2.042902 Accuracy 97.72%\n",
            "Epoch 1200/1500 Cost: 1.263322 Accuracy 98.58%\n",
            "Epoch 1300/1500 Cost: 1.082209 Accuracy 98.72%\n",
            "Epoch 1400/1500 Cost: 0.915523 Accuracy 98.88%\n",
            "Epoch 1500/1500 Cost: 0.681667 Accuracy 99.06%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-16_OO8iS8V-"
      },
      "source": [
        "# Test the model\n",
        "\n",
        "X = torch.zeros((len(test_x), 3))\n",
        "for i in range(len(test_x)):\n",
        "  X[i, :] = extract_features(test_x[i], freqs)\n",
        "\n",
        "# training labels corresponding to X\n",
        "Y = test_y\n",
        "\n",
        "model.eval()\n",
        "hypothesis = model(X)\n",
        "\n",
        "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "correct_prediction = prediction.float() == Y\n",
        "accuracy = correct_prediction.sum().item() / len(correct_prediction)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1FSyYLSGvwU",
        "outputId": "3594a5dc-4ac3-4da3-f200-a1b054fdd224"
      },
      "source": [
        " print(\"Logistic regression model's accuracy =\", accuracy * 100, \"%\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic regression model's accuracy = 98.6 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0dm3-HPV5nu",
        "outputId": "5502d8c2-db4e-4f6e-a867-4f8b2cecb98d"
      },
      "source": [
        "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n",
        "print(my_tweet)\n",
        "X = torch.zeros((1, 3))\n",
        "X[0, :] = extract_features(my_tweet, freqs)\n",
        "\n",
        "model.eval()\n",
        "hypothesis = model(X)\n",
        "\n",
        "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "print(f\"- prediction: {'Positive sentiment' if prediction else 'Negative sentiment'}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!\n",
            "- prediction: Negative sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgGtqnf1bY7G",
        "outputId": "c26b08fc-651d-478f-fda8-5cfb1ae0256f"
      },
      "source": [
        "my_tweet = 'I\\'m happy :)'\n",
        "print(my_tweet)\n",
        "X = torch.zeros((1, 3))\n",
        "X[0, :] = extract_features(my_tweet, freqs)\n",
        "\n",
        "model.eval()\n",
        "hypothesis = model(X)\n",
        "\n",
        "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "print(f\"- prediction: {'Positive sentiment' if prediction else 'Negative sentiment'}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I'm happy :)\n",
            "- prediction: Positive sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jLC7UurbiC4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}